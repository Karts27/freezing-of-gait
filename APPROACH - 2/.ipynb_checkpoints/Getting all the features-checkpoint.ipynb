{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "proprietary-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.signal import butter, lfilter\n",
    "import statistics\n",
    "import scipy.linalg as la\n",
    "from scipy.signal import periodogram\n",
    "os.chdir(r'F:\\KARTIK\\2021\\Freezing of Gait')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "changing-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\n",
    "                    os.getcwd(),\n",
    "                    'dataset_fog_release',\n",
    "                    'dataset'\n",
    "                    )\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"Path Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "future-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_prefog(dataset, window_length = 1):\n",
    "    # Drop all the rows for which Action is 0 or the rows which are not part of the experiment\n",
    "    dataset.drop(index = list(dataset[dataset['Action'] == 0].index),\n",
    "                 inplace = True)\n",
    "    \n",
    "    window_length = 64*window_length\n",
    "    \n",
    "    fog_index = []\n",
    "    for i in dataset.index:\n",
    "        if dataset.loc[i, 'Action'] == 2:\n",
    "            fog_index.append(i)\n",
    "    fog_index\n",
    "    \n",
    "    \n",
    "    start_indices = []\n",
    "    for i in fog_index:\n",
    "        if (dataset.loc[i-1, 'Action'] != dataset.loc[i, 'Action']):\n",
    "            start_indices.append(i)\n",
    "    \n",
    "    prefog = []\n",
    "    for start in start_indices:\n",
    "        prefog_start = [x for x in range(start-window_length, start)]\n",
    "        prefog.append(prefog_start)\n",
    "        \n",
    "    prefog = [item for sublist in prefog for item in sublist]\n",
    "    \n",
    "    for i in prefog:\n",
    "        dataset.loc[i,'Action'] = 3\n",
    "    dataset['Action'] = dataset['Action'] - 1\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "concrete-likelihood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01\n",
      "S01R01.txt  is read\tAdding S01R01.txt to dataset\tS01R01.txt is labelled\n",
      "S01\n",
      "S01R02.txt  is read\tAdding S01R02.txt to dataset\tS01R02.txt is labelled\n",
      "S02\n",
      "S02R01.txt  is read\tAdding S02R01.txt to dataset\tS02R01.txt is labelled\n",
      "S02\n",
      "S02R02.txt  is read\tAdding S02R02.txt to dataset\tS02R02.txt is labelled\n",
      "S03\n",
      "S03R01.txt  is read\tAdding S03R01.txt to dataset\tS03R01.txt is labelled\n",
      "S03\n",
      "S03R02.txt  is read\tAdding S03R02.txt to dataset\tS03R02.txt is labelled\n",
      "S03\n",
      "S03R03.txt  is read\tS04\n",
      "S04R01.txt  is read\tS05\n",
      "S05R01.txt  is read\tAdding S05R01.txt to dataset\tS05R01.txt is labelled\n",
      "S05\n",
      "S05R02.txt  is read\tAdding S05R02.txt to dataset\tS05R02.txt is labelled\n",
      "S06\n",
      "S06R01.txt  is read\tAdding S06R01.txt to dataset\tS06R01.txt is labelled\n",
      "S06\n",
      "S06R02.txt  is read\tS07\n",
      "S07R01.txt  is read\tAdding S07R01.txt to dataset\tS07R01.txt is labelled\n",
      "S07\n",
      "S07R02.txt  is read\tAdding S07R02.txt to dataset\tS07R02.txt is labelled\n",
      "S08\n",
      "S08R01.txt  is read\tAdding S08R01.txt to dataset\tS08R01.txt is labelled\n",
      "S09\n",
      "S09R01.txt  is read\tAdding S09R01.txt to dataset\tS09R01.txt is labelled\n",
      "S10\n",
      "S10R01.txt  is read\t"
     ]
    }
   ],
   "source": [
    "people = []\n",
    "\n",
    "for person in os.listdir(data_path):\n",
    "    if '.txt' in person:\n",
    "        people.append(person)\n",
    "\n",
    "for window_length in range(1,2):\n",
    "    dataset = pd.DataFrame()\n",
    "    for person in people:\n",
    "        name = person.split('R')[0]\n",
    "        print(name)\n",
    "        file = data_path + \"\\\\\" + person\n",
    "        temp = pd.read_csv(file, delimiter = \" \", header = None)\n",
    "        print(person, ' is read', end = \"\\t\")\n",
    "        \n",
    "        if 2 in temp[max(temp.columns)].unique():\n",
    "            print(\"Adding {} to dataset\".format(person), end = \"\\t\")\n",
    "            temp.columns = [\n",
    "                            'time',\n",
    "                            'A_F', 'A_V', 'A_L',\n",
    "                            'L_F', 'L_V', 'L_L',\n",
    "                            'T_F', 'T_V', 'T_L',\n",
    "                            'Action'                           \n",
    "                           ]\n",
    "            temp = label_prefog(temp, window_length).reset_index(drop = True)\n",
    "            #temp['name'] = name\n",
    "            print(\"{} is labelled\".format(person))\n",
    "            \n",
    "            to_name = os.getcwd() + \"\\\\APPROACH - 2\" + \"\\\\raw_labelled\" + \"\\\\\" + person[:6]  +  \".csv\"\n",
    "            \n",
    "            temp.to_csv(to_name, index = False)\n",
    "                \n",
    "#             dataset = pd.concat([dataset, temp],axis = 0)\n",
    "            \n",
    "#         print('')\n",
    "        \n",
    "#         dataset.reset_index(drop = True, inplace = True)\n",
    "#         to_path = data_path + \"\\\\raw_labelled\"\n",
    "#         to_name = to_path + \"\\\\win_\" + str(window_length) + \".csv\"\n",
    "        \n",
    "#         dataset.to_csv(to_name, index = False)\n",
    "\n",
    "# display(dataset.head())   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-progress",
   "metadata": {},
   "source": [
    "Extracting non overlapping windows of length w * f_s from the accelerometer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "historical-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(act,window_length,dataframe):\n",
    "    \n",
    "   # Get the indices of all the 0s in first loop, then all the 1s in the second and lastly, all the 2s in the third loop \n",
    "  indices = list(dataframe[dataframe.Action == act].index)\n",
    "  groups = []\n",
    "  temp = []\n",
    "  group_count = 0\n",
    "  for i in range(len(indices)):\n",
    "        \n",
    "    if i == len(indices)-1:                  # If it is the last value\n",
    "       \n",
    "      temp.append(indices[i])                # Add the last value\n",
    "      groups.append(temp)\n",
    "      temp = []\n",
    "      break\n",
    "    temp.append(indices[i])\n",
    "    \n",
    "    if indices[i]+1 != indices[i+1]:       # If consecutive values are not same\n",
    "      group_count+=1\n",
    "      groups.append(temp)\n",
    "      temp = []\n",
    "\n",
    "  fs = 64\n",
    "  window_length = 1\n",
    "  # window_length = window_length*fs\n",
    "\n",
    "  final_dataframe = pd.DataFrame()\n",
    "  for i in groups: \n",
    "    required = math.floor(len(i)/(window_length*fs))\n",
    "    \n",
    "    req_index = i[0:(required*fs)]\n",
    "    \n",
    "    final_dataframe = pd.concat([final_dataframe,dataframe.iloc[req_index,:]],axis = 0)\n",
    "  return final_dataframe\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "global-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_length in range(1,2):\n",
    "    path = os.getcwd() + \"\\\\APPROACH - 2\" + \"\\\\raw_labelled\"\n",
    "      #name = path+\"/raw_labelled/win_\"+str(window_length)+\".csv\"\n",
    "    for name in os.listdir(path):\n",
    "        dataframe = pd.read_csv(os.path.join(path, name))\n",
    "\n",
    "        activities = []\n",
    "        for act in range(3):\n",
    "            activities.append(create_window(act,window_length,dataframe))\n",
    "            to_write = pd.concat(activities,axis = 0)\n",
    "            to_path = os.getcwd() + \"\\\\APPROACH - 2\"  + \"/window\"+\"/windowed_\"+ name[:-4] +\".csv\"\n",
    "            to_write.to_csv(to_path,index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-produce",
   "metadata": {},
   "source": [
    "## Features to be extracted:\n",
    "1. Minimum\n",
    "2. Maximum\n",
    "3. Median\n",
    "4. Mean\n",
    "5. ArmMean\n",
    "6. Root Mean Square (RMS)\n",
    "7. GeoMean\n",
    "8. Variance\n",
    "9. Standard Deviation\n",
    "10. Kurtosis\n",
    "11. Skewness\n",
    "12. Mode\n",
    "13. TrimMean\n",
    "14. Entropy\n",
    "15. Asymmetry Coefficient\n",
    "16. Zero Crossing Rate (ZCR)\n",
    "17. Mean Crossing Rate (MCR)\n",
    "18. Range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "smaller-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr(array):\n",
    "    array = np.array(array)\n",
    "    x =  np.diff((array) > 0)\n",
    "    return len(np.nonzero(x)[0])\n",
    "\n",
    "def getZeroCrossingRate(arr):\n",
    "    my_array = np.array(arr)\n",
    "    return float(\"{0:.2f}\".format((((my_array[:-1] * my_array[1:]) < 0).sum())/len(arr)))\n",
    "\n",
    "def getMeanCrossingRate(arr):\n",
    "    return getZeroCrossingRate(np.array(arr) - np.mean(arr))\n",
    "\n",
    "def getMode(arr):\n",
    "    l = []\n",
    "    for ele in arr:\n",
    "        l.append(ele)\n",
    "    return statistics.mode(l)\n",
    "\n",
    "def geometric_mean(values):\n",
    "    for i in range(0, len(values)):\n",
    "        if values[i] == 0:\n",
    "            del values[i]\n",
    "        if len(values) == 0:\n",
    "            return 0\n",
    "    return np.prod([x for x in values]) ** (1 / len([x for x in values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "graduate-maryland",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened File:  windowed_S01R01.csv\n",
      "windowed_S01R01.csv \t A_F\n",
      "windowed_S01R01.csv \t A_V\n",
      "windowed_S01R01.csv \t A_L\n",
      "windowed_S01R01.csv \t L_F\n",
      "windowed_S01R01.csv \t L_V\n",
      "windowed_S01R01.csv \t L_L\n",
      "windowed_S01R01.csv \t T_F\n",
      "windowed_S01R01.csv \t T_V\n",
      "windowed_S01R01.csv \t T_L\n",
      "The shape of the dataset is:  (1434, 135)\n",
      "Saving File:  windowed_S01R01.csv\n",
      "Opened File:  windowed_S01R02.csv\n",
      "windowed_S01R02.csv \t A_F\n",
      "windowed_S01R02.csv \t A_V\n",
      "windowed_S01R02.csv \t A_L\n",
      "windowed_S01R02.csv \t L_F\n",
      "windowed_S01R02.csv \t L_V\n",
      "windowed_S01R02.csv \t L_L\n",
      "windowed_S01R02.csv \t T_F\n",
      "windowed_S01R02.csv \t T_V\n",
      "windowed_S01R02.csv \t T_L\n",
      "The shape of the dataset is:  (446, 135)\n",
      "Saving File:  windowed_S01R02.csv\n",
      "Opened File:  windowed_S02R01.csv\n",
      "windowed_S02R01.csv \t A_F\n",
      "windowed_S02R01.csv \t A_V\n",
      "windowed_S02R01.csv \t A_L\n",
      "windowed_S02R01.csv \t L_F\n",
      "windowed_S02R01.csv \t L_V\n",
      "windowed_S02R01.csv \t L_L\n",
      "windowed_S02R01.csv \t T_F\n",
      "windowed_S02R01.csv \t T_V\n",
      "windowed_S02R01.csv \t T_L\n",
      "The shape of the dataset is:  (392, 135)\n",
      "Saving File:  windowed_S02R01.csv\n",
      "Opened File:  windowed_S02R02.csv\n",
      "windowed_S02R02.csv \t A_F\n",
      "windowed_S02R02.csv \t A_V\n",
      "windowed_S02R02.csv \t A_L\n",
      "windowed_S02R02.csv \t L_F\n",
      "windowed_S02R02.csv \t L_V\n",
      "windowed_S02R02.csv \t L_L\n",
      "windowed_S02R02.csv \t T_F\n",
      "windowed_S02R02.csv \t T_V\n",
      "windowed_S02R02.csv \t T_L\n",
      "The shape of the dataset is:  (1001, 135)\n",
      "Saving File:  windowed_S02R02.csv\n",
      "Opened File:  windowed_S03R01.csv\n",
      "windowed_S03R01.csv \t A_F\n",
      "windowed_S03R01.csv \t A_V\n",
      "windowed_S03R01.csv \t A_L\n",
      "windowed_S03R01.csv \t L_F\n",
      "windowed_S03R01.csv \t L_V\n",
      "windowed_S03R01.csv \t L_L\n",
      "windowed_S03R01.csv \t T_F\n",
      "windowed_S03R01.csv \t T_V\n",
      "windowed_S03R01.csv \t T_L\n",
      "The shape of the dataset is:  (1379, 135)\n",
      "Saving File:  windowed_S03R01.csv\n",
      "Opened File:  windowed_S03R02.csv\n",
      "windowed_S03R02.csv \t A_F\n",
      "windowed_S03R02.csv \t A_V\n",
      "windowed_S03R02.csv \t A_L\n",
      "windowed_S03R02.csv \t L_F\n",
      "windowed_S03R02.csv \t L_V\n",
      "windowed_S03R02.csv \t L_L\n",
      "windowed_S03R02.csv \t T_F\n",
      "windowed_S03R02.csv \t T_V\n",
      "windowed_S03R02.csv \t T_L\n",
      "The shape of the dataset is:  (254, 135)\n",
      "Saving File:  windowed_S03R02.csv\n",
      "Opened File:  windowed_S05R01.csv\n",
      "windowed_S05R01.csv \t A_F\n",
      "windowed_S05R01.csv \t A_V\n",
      "windowed_S05R01.csv \t A_L\n",
      "windowed_S05R01.csv \t L_F\n",
      "windowed_S05R01.csv \t L_V\n",
      "windowed_S05R01.csv \t L_L\n",
      "windowed_S05R01.csv \t T_F\n",
      "windowed_S05R01.csv \t T_V\n",
      "windowed_S05R01.csv \t T_L\n",
      "The shape of the dataset is:  (1018, 135)\n",
      "Saving File:  windowed_S05R01.csv\n",
      "Opened File:  windowed_S05R02.csv\n",
      "windowed_S05R02.csv \t A_F\n",
      "windowed_S05R02.csv \t A_V\n",
      "windowed_S05R02.csv \t A_L\n",
      "windowed_S05R02.csv \t L_F\n",
      "windowed_S05R02.csv \t L_V\n",
      "windowed_S05R02.csv \t L_L\n",
      "windowed_S05R02.csv \t T_F\n",
      "windowed_S05R02.csv \t T_V\n",
      "windowed_S05R02.csv \t T_L\n",
      "The shape of the dataset is:  (1003, 135)\n",
      "Saving File:  windowed_S05R02.csv\n",
      "Opened File:  windowed_S06R01.csv\n",
      "windowed_S06R01.csv \t A_F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windowed_S06R01.csv \t A_V\n",
      "windowed_S06R01.csv \t A_L\n",
      "windowed_S06R01.csv \t L_F\n",
      "windowed_S06R01.csv \t L_V\n",
      "windowed_S06R01.csv \t L_L\n",
      "windowed_S06R01.csv \t T_F\n",
      "windowed_S06R01.csv \t T_V\n",
      "windowed_S06R01.csv \t T_L\n",
      "The shape of the dataset is:  (1670, 135)\n",
      "Saving File:  windowed_S06R01.csv\n",
      "Opened File:  windowed_S07R01.csv\n",
      "windowed_S07R01.csv \t A_F\n",
      "windowed_S07R01.csv \t A_V\n",
      "windowed_S07R01.csv \t A_L\n",
      "windowed_S07R01.csv \t L_F\n",
      "windowed_S07R01.csv \t L_V\n",
      "windowed_S07R01.csv \t L_L\n",
      "windowed_S07R01.csv \t T_F\n",
      "windowed_S07R01.csv \t T_V\n",
      "windowed_S07R01.csv \t T_L\n",
      "The shape of the dataset is:  (1145, 135)\n",
      "Saving File:  windowed_S07R01.csv\n",
      "Opened File:  windowed_S07R02.csv\n",
      "windowed_S07R02.csv \t A_F\n",
      "windowed_S07R02.csv \t A_V\n",
      "windowed_S07R02.csv \t A_L\n",
      "windowed_S07R02.csv \t L_F\n",
      "windowed_S07R02.csv \t L_V\n",
      "windowed_S07R02.csv \t L_L\n",
      "windowed_S07R02.csv \t T_F\n",
      "windowed_S07R02.csv \t T_V\n",
      "windowed_S07R02.csv \t T_L\n",
      "The shape of the dataset is:  (442, 135)\n",
      "Saving File:  windowed_S07R02.csv\n",
      "Opened File:  windowed_S08R01.csv\n",
      "windowed_S08R01.csv \t A_F\n",
      "windowed_S08R01.csv \t A_V\n",
      "windowed_S08R01.csv \t A_L\n",
      "windowed_S08R01.csv \t L_F\n",
      "windowed_S08R01.csv \t L_V\n",
      "windowed_S08R01.csv \t L_L\n",
      "windowed_S08R01.csv \t T_F\n",
      "windowed_S08R01.csv \t T_V\n",
      "windowed_S08R01.csv \t T_L\n",
      "The shape of the dataset is:  (759, 135)\n",
      "Saving File:  windowed_S08R01.csv\n",
      "Opened File:  windowed_S09R01.csv\n",
      "windowed_S09R01.csv \t A_F\n",
      "windowed_S09R01.csv \t A_V\n",
      "windowed_S09R01.csv \t A_L\n",
      "windowed_S09R01.csv \t L_F\n",
      "windowed_S09R01.csv \t L_V\n",
      "windowed_S09R01.csv \t L_L\n",
      "windowed_S09R01.csv \t T_F\n",
      "windowed_S09R01.csv \t T_V\n",
      "windowed_S09R01.csv \t T_L\n",
      "The shape of the dataset is:  (1711, 135)\n",
      "Saving File:  windowed_S09R01.csv\n"
     ]
    }
   ],
   "source": [
    "window_length = 1\n",
    "f_s = 64\n",
    "w = window_length * f_s\n",
    "\n",
    "FE_path = os.getcwd() + \"\\\\APPROACH - 2\"  + \"\\\\window\"\n",
    "\n",
    "for file in os.listdir(FE_path):\n",
    "    #print(file)\n",
    "    print(\"Opened File: \" , file, end  = \"\\n\")\n",
    "    name = os.path.join(FE_path, file)\n",
    "    dataframe = pd.read_csv(name)\n",
    "    df = dataframe.drop(columns = ['time', 'Action'])\n",
    "    statistics = pd.DataFrame()\n",
    "\n",
    "    col = list(df.columns)\n",
    "    for column in col:\n",
    "        print(file, \"\\t\", column)\n",
    "\n",
    "        f1 = []\n",
    "        f2 = []\n",
    "        f3 = []\n",
    "        f4 = []\n",
    "        f5 = []\n",
    "        f6 = []\n",
    "        f7 = []\n",
    "        f8 = []\n",
    "        f9 = []\n",
    "        f10 = []\n",
    "        f11 = []\n",
    "        f12 = []\n",
    "        f13 = []\n",
    "        f14 = []\n",
    "        f15 = []\n",
    "        f16 = []\n",
    "        f17 = []\n",
    "        f18 = []\n",
    "\n",
    "        for i in range(0, len(df), w):\n",
    "            f_1 = min(df[column].iloc[i:i+w])\n",
    "            f_2 = max(df[column].iloc[i:i+w])\n",
    "            f_3 = np.median(df[column].iloc[i:i+w])\n",
    "            f_4 = np.mean(df[column].iloc[i:i+w])\n",
    "            f_5 = stats.hmean(abs(df[column].iloc[i:i+w]))\n",
    "\n",
    "            f_6 = np.sqrt(np.mean(df[column].iloc[i:i+w]**2))\n",
    "\n",
    "    #        f_7 = geometric_mean(df[column].iloc[i:i+w])\n",
    "            f_8 = np.var(df[column].iloc[i:i+w])\n",
    "            f_9 = np.std(df[column].iloc[i:i+w])\n",
    "            f_10 = stats.kurtosis(df[column].iloc[i:i+w])\n",
    "            f_11 = stats.skew(df[column].iloc[i:i+w])\n",
    "            #f_12 = getMode(df[column].iloc[i:i+w])\n",
    "            f_13 = stats.tmean(df[column].iloc[i:i+w])\n",
    "            #f_14 = stats.entropy(df[column].iloc[i:i+w])\n",
    "            f_15 = df[column].iloc[i] / np.std(df[column].iloc[i:i+w])\n",
    "            f_16 = getZeroCrossingRate(df[column].iloc[i:i+w])\n",
    "            f_17 = getMeanCrossingRate(df[column].iloc[i:i+w])\n",
    "            f_18 = f_2 - f_1\n",
    "\n",
    "\n",
    "            f1.append(f_1)\n",
    "            f2.append(f_2)\n",
    "            f3.append(f_3)\n",
    "            f4.append(f_4)\n",
    "            f5.append(f_5)\n",
    "            f6.append(f_6)\n",
    "            #f7.append(f_7)\n",
    "            f8.append(f_8)\n",
    "            f9.append(f_9)\n",
    "            f10.append(f_10)\n",
    "            f11.append(f_11)\n",
    "    #         f12.append(f_12)\n",
    "            f13.append(f_13)\n",
    "            #f14.append(f_14)\n",
    "            f15.append(f_15)\n",
    "            f16.append(f_16)\n",
    "            f17.append(f_17)\n",
    "            f18.append(f_18)\n",
    "\n",
    "        statistics['Minimum_' + column] = f1\n",
    "        statistics['Maximum_' + column] = f2\n",
    "        statistics['Median_' + column] = f3\n",
    "        statistics['Mean_' + column] = f4\n",
    "        statistics['ArmMean_' + column] = f5\n",
    "        statistics['RMS_' + column] = f6\n",
    "        #statistics['GeometricMean_' + column] = f7\n",
    "        statistics['Variance_' + column] = f8\n",
    "        statistics['STD_' + column] = f9\n",
    "        statistics['Kurtosis_' + column] = f10\n",
    "        statistics['Skewness_' + column] = f11\n",
    "        #statistics['Mode_' + column] = f12\n",
    "        statistics['TrimMean_' + column] = f13\n",
    "        #statistics['Entropy_' + column] = f14\n",
    "        statistics['AsymmetryCoefficient_' + column] = f15\n",
    "        statistics['ZCR_' + column] = f16\n",
    "        statistics['MCR_' + column] = f17\n",
    "        statistics['Range' + column] = f18    \n",
    "\n",
    "    print(\"The shape of the dataset is: \", statistics.shape)\n",
    "    statistics1 = copy.copy(statistics)\n",
    "    statistics1['w'] = dataframe['Action'].iloc[[x for x in range(0, len(dataframe), w)]].to_list()\n",
    "    order = ['w']\n",
    "    order += statistics1.columns.to_list()[:-1]\n",
    "    statistics1 = statistics1[order]\n",
    "    statistics1.columns\n",
    "    col = statistics1.columns.to_list()\n",
    "    col[0] = 0\n",
    "    statistics1.columns = col\n",
    "    feature_name = os.getcwd() + \"\\\\APPROACH - 2\"  + \"/features\"+\"/time_\"+ file[:-4] +\".csv\"\n",
    "    print(\"Saving File: \", file)\n",
    "    statistics1.to_csv(feature_name, index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "assigned-surrey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened File:  windowed_S01R01.csv\n",
      "A_F done A_V done A_L done L_F done L_V done L_L done T_F done T_V done T_L done  Freezing Index and Power has been calculated\n",
      "(1434, 45)\n",
      "Opened File:  windowed_S01R02.csv\n",
      "A_F done A_V done A_L done L_F done L_V done L_L done T_F done T_V done T_L done  Freezing Index and Power has been calculated\n",
      "(446, 45)\n",
      "Opened File:  windowed_S02R01.csv\n",
      "A_F done A_V done A_L done L_F done L_V done L_L done T_F done T_V done T_L done  Freezing Index and Power has been calculated\n",
      "(392, 45)\n",
      "Opened File:  windowed_S02R02.csv\n",
      "A_F done A_V done A_L done L_F done L_V done L_L done T_F done T_V done T_L done  Freezing Index and Power has been calculated\n",
      "(1001, 45)\n",
      "Opened File:  windowed_S03R01.csv\n",
      "A_F done A_V done A_L done L_F done L_V done L_L done T_F done T_V done T_L done  Freezing Index and Power has been calculated\n",
      "(1379, 45)\n",
      "Opened File:  windowed_S03R02.csv\n",
      "A_F done A_V done A_L done L_F done L_V done L_L done T_F done T_V done T_L done  Freezing Index and Power has been calculated\n",
      "(254, 45)\n",
      "Opened File:  windowed_S05R01.csv\n",
      "A_F done A_V done A_L done L_F done L_V done L_L done T_F done T_V done T_L done  Freezing Index and Power has been calculated\n",
      "(1018, 45)\n",
      "Opened File:  windowed_S05R02.csv\n",
      "A_F done A_V done A_L done L_F done L_V done L_L done T_F done T_V done T_L done  Freezing Index and Power has been calculated\n",
      "(1003, 45)\n",
      "Opened File:  windowed_S06R01.csv\n",
      "A_F done A_V done A_L done L_F done L_V done L_L done T_F done T_V done T_L done  Freezing Index and Power has been calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:87: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1670, 45)\n",
      "Opened File:  windowed_S07R01.csv\n",
      "A_F done A_V done A_L done L_F done L_V done L_L done T_F done T_V done T_L done  Freezing Index and Power has been calculated\n",
      "(1145, 45)\n",
      "Opened File:  windowed_S07R02.csv\n",
      "A_F done A_V done A_L done L_F done L_V done L_L done T_F done T_V done T_L done  Freezing Index and Power has been calculated\n",
      "(442, 45)\n",
      "Opened File:  windowed_S08R01.csv\n",
      "A_F done A_V done A_L done L_F done L_V done L_L done T_F done T_V done T_L done  Freezing Index and Power has been calculated\n",
      "(759, 45)\n",
      "Opened File:  windowed_S09R01.csv\n",
      "A_F done A_V done A_L done L_F done L_V done L_L done T_F done T_V done T_L done  Freezing Index and Power has been calculated\n",
      "(1711, 45)\n"
     ]
    }
   ],
   "source": [
    "window_length = 1\n",
    "f_s = 64\n",
    "w = window_length * f_s\n",
    "\n",
    "FE_path = os.getcwd() + \"\\\\APPROACH - 2\"  + \"\\\\window\"\n",
    "\n",
    "for file in os.listdir(FE_path):\n",
    "    #print(file)\n",
    "    print(\"Opened File: \" , file, end  = \"\\n\")\n",
    "    name = os.path.join(FE_path, file)\n",
    "    dataframe = pd.read_csv(name)\n",
    "    df = dataframe.drop(columns = ['time', 'Action'])\n",
    "    fi = pd.DataFrame()\n",
    "    power = pd.DataFrame()\n",
    "    order = 5\n",
    "    bands = {'locomotor' : (0.5,3), 'freeze' : (3,8)}\n",
    "    col = list(df.columns)\n",
    "\n",
    "\n",
    "    for column in col:\n",
    "        xtemp = []\n",
    "        xtemp1 = []\n",
    "        for i in range(0, len(df),w):\n",
    "            nyq = 0.5*f_s             # Nyquist Rate\n",
    "\n",
    "            # LOCOMOTOR HAS A FREQUENCY RANGE OF 0.5Hz - 3Hz FOR TOTAL POWER\n",
    "\n",
    "            loc_low = 0.5 / nyq\n",
    "            loc_high = 3 / nyq\n",
    "\n",
    "            # Clipping off band from the window\n",
    "\n",
    "            b, a = butter(order, [loc_low, loc_high], btype = 'band')\n",
    "            y = lfilter(b, a, df[column].iloc[i:i+w])\n",
    "\n",
    "            # Total power in locomotor band\n",
    "\n",
    "            e1 = sum([x**2 for x in y])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # FREEZING BAND HAS A FREQUENCY RANGE OF 3Hz - 8Hz\n",
    "\n",
    "            frez_low = 3 / nyq\n",
    "            frez_high = 8 / nyq\n",
    "\n",
    "            # Clipping off band from the window\n",
    "\n",
    "            b1, a1 = butter(order, [frez_low, frez_high], btype = 'band')\n",
    "            y1 = lfilter(b1, a1, df[column].iloc[i:i+w])\n",
    "\n",
    "            # Total power in freezing band\n",
    "\n",
    "            e2 = sum([x**2 for x in y1])\n",
    "\n",
    "            freezing_index = e2/e1\n",
    "            pwr = e2 + e1\n",
    "\n",
    "            xtemp.append(freezing_index)\n",
    "            xtemp1.append(pwr)\n",
    "\n",
    "        print(column + \" done\", end = \" \")\n",
    "\n",
    "        fi['FI_' + column] = xtemp\n",
    "        power['P_' + column] = xtemp1\n",
    "\n",
    "    print(\" Freezing Index and Power has been calculated\")\n",
    "\n",
    "    E = []\n",
    "\n",
    "    for i in range(0, len(df), w):\n",
    "        energy = np.sum((df.iloc[i:i + w,:])**2)\n",
    "        E.append(energy)\n",
    "\n",
    "    E = pd.DataFrame(E)\n",
    "\n",
    "    E.columns = [\"EN_\" + x for x in df.columns]\n",
    "\n",
    "    peak_f = pd.DataFrame()\n",
    "    PSE = pd.DataFrame()\n",
    "    for s in col:\n",
    "      peakF = []\n",
    "      pse = []\n",
    "      for i in range(0,len(df),w):\n",
    "          f,Pxx_den = periodogram(df[s].iloc[i:i+w],w)\n",
    "          p_norm = Pxx_den/sum(Pxx_den)\n",
    "          p_norm = list(filter(lambda a: a != 0, p_norm))\n",
    "          pse.append(-(np.sum(p_norm*np.log(p_norm))))\n",
    "          peak = (f_s/w)*max(Pxx_den)\n",
    "          peakF.append(peak)\n",
    "      PSE['ENt_'+s] = pse\n",
    "      peak_f['peak_'+s] = peakF\n",
    "    PSE.fillna(0,inplace = True)\n",
    "\n",
    "    freq = pd.concat([fi, power, E, peak_f, PSE], axis = 1)\n",
    "\n",
    "    print(freq.shape)\n",
    "    feature_name = os.getcwd() + \"\\\\APPROACH - 2\"  + \"/features\"+\"/freq_\"+ file[:-4] +\".csv\"\n",
    "\n",
    "    freq.to_csv(feature_name, index = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "romantic-primary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time_windowed_S01R01.csv', 'time_windowed_S01R02.csv', 'time_windowed_S02R01.csv', 'time_windowed_S02R02.csv', 'time_windowed_S03R01.csv', 'time_windowed_S03R02.csv', 'time_windowed_S05R01.csv', 'time_windowed_S05R02.csv', 'time_windowed_S06R01.csv', 'time_windowed_S07R01.csv', 'time_windowed_S07R02.csv', 'time_windowed_S08R01.csv', 'time_windowed_S09R01.csv']\n"
     ]
    }
   ],
   "source": [
    "data_path_1 = os.getcwd() + \"\\\\APPROACH - 2\"  + \"\\\\features\" + \"\\\\frequency\"\n",
    "fr = os.listdir(data_path_1)\n",
    "\n",
    "data_path_2 = os.getcwd() + \"\\\\APPROACH - 2\"  + \"\\\\features\" + \"\\\\time\"\n",
    "ti = os.listdir(data_path_2)\n",
    "\n",
    "total_files = len(fr)\n",
    "print(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "phantom-stable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01R01\n",
      "S01R02\n",
      "S02R01\n",
      "S02R02\n",
      "S03R01\n",
      "S03R02\n",
      "S05R01\n",
      "S05R02\n",
      "S06R01\n",
      "S07R01\n",
      "S07R02\n",
      "S08R01\n",
      "S09R01\n"
     ]
    }
   ],
   "source": [
    "for i in range(13):\n",
    "    fr_path = os.path.join(data_path_1, fr[i])\n",
    "    ti_path = os.path.join(data_path_2, ti[i])\n",
    "    if os.path.exists(fr_path) and os.path.exists(ti_path):\n",
    "        fr_file = pd.read_csv(fr_path)\n",
    "        ti_file = pd.read_csv(ti_path)\n",
    "        \n",
    "        final_features = pd.concat([ti_file, fr_file], axis = 1)\n",
    "        #print(final_features.head(1))\n",
    "        print(fr[i][-10:-4])\n",
    "        \n",
    "        feature_name = os.getcwd() + \"\\\\APPROACH - 2\"  +  \"\\\\final_features\" + fr[i][-10:-4] +  \".csv\"\n",
    "        \n",
    "        final_features.to_csv(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-defendant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
